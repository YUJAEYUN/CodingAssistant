#!/usr/bin/env python3
"""
ìŠ¤ë§ˆíŠ¸ ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ - í™”ë©´ ìº¡ì²˜ ë° AI ë¶„ì„ ë„êµ¬

ì‚¬ìš©ìì˜ í™”ë©´ì„ ìº¡ì²˜í•˜ê³  AIë¡œ ë¶„ì„í•˜ì—¬ ì½”ë“œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
"""

import os
import sys
import time
import base64
import threading
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any

import pyautogui
import keyboard
from PIL import Image, ImageGrab
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn

from utils.llm_client import get_client


class ScreenAssistant:
    """í™”ë©´ ìº¡ì²˜ ë° AI ë¶„ì„ì„ ë‹´ë‹¹í•˜ëŠ” ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.console = Console()
        self.client = None
        self.is_running = False
        self.screenshots_dir = Path("screenshots")
        self.screenshots_dir.mkdir(exist_ok=True)
        
        # API í‚¤ í™•ì¸
        if "ANTHROPIC_API_KEY" not in os.environ:
            self.console.print("[red]âŒ ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤![/red]")
            sys.exit(1)
            
        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.client = get_client(
                "anthropic-direct",
                model_name="claude-sonnet-4-20250514",
                use_caching=True,
            )
            self.console.print("[green]âœ… AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ[/green]")
        except Exception as e:
            self.console.print(f"[red]âŒ AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}[/red]")
            sys.exit(1)
    
    def capture_screen(self, region: Optional[tuple] = None) -> str:
        """
        í™”ë©´ì„ ìº¡ì²˜í•˜ê³  íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            region: ìº¡ì²˜í•  ì˜ì—­ (x, y, width, height). Noneì´ë©´ ì „ì²´ í™”ë©´
            
        Returns:
            ì €ì¥ëœ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        """
        try:
            # í™”ë©´ ìº¡ì²˜
            if region:
                screenshot = ImageGrab.grab(bbox=region)
            else:
                screenshot = ImageGrab.grab()
            
            # íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"screen_{timestamp}.png"
            filepath = self.screenshots_dir / filename
            
            # ì´ë¯¸ì§€ ì €ì¥
            screenshot.save(filepath)
            self.console.print(f"[green]ğŸ“¸ í™”ë©´ ìº¡ì²˜ ì™„ë£Œ: {filepath}[/green]")
            
            return str(filepath)
            
        except Exception as e:
            self.console.print(f"[red]âŒ í™”ë©´ ìº¡ì²˜ ì‹¤íŒ¨: {e}[/red]")
            return ""
    
    def encode_image_to_base64(self, image_path: str) -> str:
        """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            self.console.print(f"[red]âŒ ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨: {e}[/red]")
            return ""
    
    def analyze_screen_with_prompt(self, image_path: str, user_prompt: str) -> str:
        """
        ìº¡ì²˜ëœ í™”ë©´ê³¼ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ê²°í•©í•˜ì—¬ AI ë¶„ì„
        
        Args:
            image_path: ìº¡ì²˜ëœ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            user_prompt: ì‚¬ìš©ìê°€ ì…ë ¥í•œ í”„ë¡¬í”„íŠ¸
            
        Returns:
            AI ë¶„ì„ ê²°ê³¼ ë° í•´ê²° ì½”ë“œ
        """
        try:
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            image_base64 = self.encode_image_to_base64(image_path)
            if not image_base64:
                return "ì´ë¯¸ì§€ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            
            # AI ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = """
ë‹¹ì‹ ì€ í™”ë©´ì„ ë³´ê³  ì½”ë”© ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ ì œê³µí•œ í™”ë©´ ìŠ¤í¬ë¦°ìƒ·ê³¼ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬:
1. í™”ë©´ì— í‘œì‹œëœ ë‚´ìš©ì„ ì •í™•íˆ íŒŒì•…
2. ì½”ë“œ ì—ëŸ¬, UI ë¬¸ì œ, ë˜ëŠ” ê°œë°œ ì´ìŠˆ ì‹ë³„
3. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì™€ í™”ë©´ ë‚´ìš©ì„ ê²°í•©í•˜ì—¬ ë¬¸ì œ í•´ê²°
4. ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œë‚˜ í•´ê²°ì±… ì œê³µ

ì‘ë‹µ í˜•ì‹:
## ğŸ“‹ í™”ë©´ ë¶„ì„
[í™”ë©´ì—ì„œ ë°œê²¬í•œ ë‚´ìš© ì„¤ëª…]

## ğŸ¯ ë¬¸ì œ ì‹ë³„
[ë°œê²¬ëœ ë¬¸ì œë‚˜ ì´ìŠˆ]

## ğŸ’¡ í•´ê²° ë°©ì•ˆ
[êµ¬ì²´ì ì¸ í•´ê²° ë°©ë²•]

## ğŸ’» ì½”ë“œ ì†”ë£¨ì…˜
```python
# ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ì œê³µ
```

## ğŸ“ ì¶”ê°€ ì„¤ëª…
[í•„ìš”í•œ ê²½ìš° ì¶”ê°€ ì„¤ëª…]
"""
            
            user_message = f"""
ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸: {user_prompt}

ì²¨ë¶€ëœ í™”ë©´ ìŠ¤í¬ë¦°ìƒ·ì„ ë¶„ì„í•˜ê³ , ì‚¬ìš©ìì˜ ìš”ì²­ê³¼ ê²°í•©í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•´ì£¼ì„¸ìš”.
"""

            # AI í´ë¼ì´ì–¸íŠ¸ í˜¸ì¶œ (Anthropic ì§ì ‘ ì‚¬ìš©)
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=self.console
            ) as progress:
                task = progress.add_task("ğŸ¤– AI ë¶„ì„ ì¤‘...", total=None)

                # Anthropic í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì‚¬ìš©
                import anthropic
                anthropic_client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

                response = anthropic_client.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=4000,
                    system=system_prompt,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": user_message
                                },
                                {
                                    "type": "image",
                                    "source": {
                                        "type": "base64",
                                        "media_type": "image/png",
                                        "data": image_base64
                                    }
                                }
                            ]
                        }
                    ]
                )

                progress.remove_task(task)

            return response.content[0].text
            
        except Exception as e:
            self.console.print(f"[red]âŒ AI ë¶„ì„ ì‹¤íŒ¨: {e}[/red]")
            return f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
    
    def process_request(self, user_prompt: str):
        """ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬ (í™”ë©´ ìº¡ì²˜ + AI ë¶„ì„)"""
        self.console.print(Panel(
            f"[bold blue]ğŸš€ ìš”ì²­ ì²˜ë¦¬ ì‹œì‘[/bold blue]\n"
            f"í”„ë¡¬í”„íŠ¸: {user_prompt}",
            title="Screen Assistant",
            border_style="blue"
        ))
        
        # 1. í™”ë©´ ìº¡ì²˜
        image_path = self.capture_screen()
        if not image_path:
            return
        
        # 2. AI ë¶„ì„
        result = self.analyze_screen_with_prompt(image_path, user_prompt)
        
        # 3. ê²°ê³¼ ì¶œë ¥
        self.console.print(Panel(
            result,
            title="[bold green]ğŸ¯ AI ë¶„ì„ ê²°ê³¼[/bold green]",
            border_style="green"
        ))
        
        # 4. ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_file = self.screenshots_dir / f"analysis_{timestamp}.md"
        
        with open(result_file, "w", encoding="utf-8") as f:
            f.write(f"# í™”ë©´ ë¶„ì„ ê²°ê³¼\n\n")
            f.write(f"**ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**í”„ë¡¬í”„íŠ¸**: {user_prompt}\n")
            f.write(f"**ì´ë¯¸ì§€**: {image_path}\n\n")
            f.write(result)
        
        self.console.print(f"[green]ğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {result_file}[/green]")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    assistant = ScreenAssistant()
    
    assistant.console.print(Panel(
        "[bold]ğŸ¯ ìŠ¤ë§ˆíŠ¸ ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸[/bold]\n\n"
        "í™”ë©´ì„ ìº¡ì²˜í•˜ê³  AIë¡œ ë¶„ì„í•˜ì—¬ ì½”ë”© ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.\n\n"
        "[yellow]ì‚¬ìš©ë²•:[/yellow]\n"
        "1. ë¬¸ì œê°€ ìˆëŠ” í™”ë©´ì„ ë„ì›Œë†“ìœ¼ì„¸ìš”\n"
        "2. ì•„ë˜ì— í•´ê²°í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”\n"
        "3. Enterë¥¼ ëˆ„ë¥´ë©´ í™”ë©´ì„ ìº¡ì²˜í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤\n\n"
        "[red]ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit' ì…ë ¥[/red]",
        title="Screen Assistant",
        border_style="cyan"
    ))
    
    try:
        while True:
            # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
            user_prompt = input("\nğŸ’¬ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            # ì¢…ë£Œ ëª…ë ¹ í™•ì¸
            if user_prompt.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                assistant.console.print("[bold]ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.[/bold]")
                break
            
            if not user_prompt:
                assistant.console.print("[yellow]âš ï¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.[/yellow]")
                continue
            
            # ìš”ì²­ ì²˜ë¦¬
            assistant.process_request(user_prompt)
            
    except KeyboardInterrupt:
        assistant.console.print("\n[bold]ğŸ‘‹ í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.[/bold]")


if __name__ == "__main__":
    main()
